{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anonymization of dicom\n",
    "\n",
    "<details>\n",
    "<summary>STEP 1 BIG PICTURE</summary>\n",
    "We collected data from centers in folders, named as patient ID (e.g. admission). We want to clean these directories, so \n",
    "I: Each CT study is placed in one folder\n",
    "II: Store cases in an excel file, with its dicom files in the table, and all other variables (outcome, clinical, pathology data) stored here. We call this master key, which also contains patient id (un-anonymized) along with the key for anonymization.\n",
    "III: Transfer dicom-pnly files to new destination and anonymize these images.\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>PREVIOUS STEP</summary>\n",
    "WE previously transfered all dicom files of enrolled cases to a new destination. Now we want to anynymize it.\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>THIS STEP</summary>\n",
    "This code remove dicom meta data that may represent patient identity, while preserving many useful tags within dicom metadata.\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>NEXT STEP</summary>\n",
    "Upload to Xnat for labeling and anonymization.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Files: Function and library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am using the code in 1_2_Add_Dicom_Meta_to_Table to store a json and table so I can make sure tha I can retrive the anonymized.\n",
    "# This is just another backup file that I can look for in the future (for pseuodonymization)\n",
    "\n",
    "#FINAL 20231216\n",
    "#My context: I coded this on my windows11 with RTC3080Ti and Corei9-12gen and 32G Ram. I am coding on VS code and using jupyter notebook.\n",
    "#Your requirment: It doesn't need any exceptional hardward you can run it on an average pc/labtob\n",
    "\n",
    "import pydicom as pm #for reading dicoms\n",
    "import os #for looping through system direcotries\n",
    "from pydicom.multival import MultiValue #for reading dicom metadata\n",
    "from pydicom.valuerep import PersonName #since tunring dictionary to json raised an error you should use this\n",
    "from tqdm.notebook import tqdm #for that fancy loop progress, I like it though\n",
    "import pandas as pd #for tunring dic to excel, first we trasnform it to pandas dataframe\n",
    "import json #for storing as json\n",
    "\n",
    "from IPython.display import HTML #so you can click on the sotred excel and json and open it from jupyter notebook\n",
    "\n",
    "def get_dicom_tag_value(dicom_file, tag, default=None):\n",
    "    '''this function will get the dicom tag from the dicom filde for the given tag/code'''\n",
    "    tag_value = dicom_file.get(tag, None)\n",
    "    if tag_value is None:\n",
    "        return default\n",
    "    if isinstance(tag_value, MultiValue):\n",
    "        return list(tag_value)  # Convert MultiValue to list\n",
    "    return tag_value.value\n",
    "\n",
    "def get_path_to_first_subfolder(full_path, first_subfolder):\n",
    "    \"\"\"this will get the path to the first folder of root, which is the subfolder that contains all dicom filed of one dicom study \"\"\"\n",
    "    path_parts = full_path.split(os.sep)\n",
    "    if first_subfolder in path_parts:\n",
    "        subfolder_index = path_parts.index(first_subfolder)\n",
    "        return os.sep.join(path_parts[:subfolder_index + 1])\n",
    "    else:\n",
    "        return full_path\n",
    "\n",
    "def count_subfolders(directory):\n",
    "    '''this will cont the number of files and folders within a direcotyr'''\n",
    "    total_subfolders = 0\n",
    "    total_files=0\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        total_subfolders += len(dirs)\n",
    "        total_files += len(files)\n",
    "    return total_subfolders,total_files \n",
    "\n",
    "\n",
    "class CustomJSONEncoder(json.JSONEncoder): #this class will turn our multilevel dictionary into a json file\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, MultiValue):\n",
    "            return list(obj)  # Convert MultiValue to list\n",
    "        elif isinstance(obj, PersonName):\n",
    "            return str(obj)   # Convert PersonName to string\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "def ensure_json_extension(directory): \n",
    "    '''this function will ensure that definied json direcotry contains the required extension, otherwise, it will add this to the end of definied dir'''\n",
    "    if not directory.endswith(\".json\"):\n",
    "        return directory + \"\\\\JSON.json\"\n",
    "    return directory\n",
    "\n",
    "def ensure_excel_extension(directory):\n",
    "    '''this function will ensure that definied excel direcotry contains the required extension, otherwise, it will add this to the end of definied dir'''\n",
    "    if not directory.endswith(\".xlsx\"):\n",
    "        return directory + \"\\\\excel.xlsx\"\n",
    "    return directory\n",
    "\n",
    "def create_clickable_dir_path(dir_path):\n",
    "    # Convert the directory path to a file URL\n",
    "    file_url = f\"{dir_path}\"\n",
    "    return HTML(f'<a href=\"{file_url}\" target=\"_blank\">{dir_path}</a>')\n",
    "\n",
    "\n",
    "\n",
    "def get_dicomdir_give_dicomdicom_datadic(dicom_dir, #direcotry that you want to read, usually dicom studies should be in one folder, preferably with patient unique id/name\n",
    "                                     dicom_validation=True, #this will check wether the file in the loop is dicom or not. Although make it slower, I recommend using it to ensure only dicom files go through loop \n",
    "                                     folder_list_name_indicomdir=None, #In your dicom_dir you can include list of folders name that you want to read. It will not read other folders. Kepp in mind that this will look into subfolders in the main folder, and not the subfolders of subfolders :)\n",
    "                                     store_as_json_dir=None, #if you want to store your ditionary as json, give your desired json direcotry\n",
    "                                     store_as_excel_dir=None #if you want to store your ditionary as excel, give your desired excel direcotry\n",
    "                                     ):\n",
    "    \"\"\"\n",
    "    This function creates a multi-level dictionary for DICOM meta data (named dicom_data) in a directory (named dicom_dir).\n",
    "    The top level has the last component of dicom_dir, which is the first level subfolder, as a key.\n",
    "    For each subforled it will store study data within this dic, along with another dicitonary for series data, within this study dictionary.\n",
    "    For series dictionary the data corresponding for series number will be stored.\n",
    "    We also have another private_info dictionary within subfodler dictionary.\n",
    "    \n",
    "    - dicom_validation: If you set dicom_validation=True, it will validate the file in the loop for being an dicom file. This is super important although it makes code slower.\n",
    "    Becaouse, sometimes some dicom files have no extension, and also reading other files may cause error in the loop.\n",
    "    \n",
    "    - folder_list_name_indicomdir: #In your dicom_dir you can include list of folders name that you want to read. It will not read other folders. Kepp in mind that this will look into subfolders in the main folder, and not the subfolders of subfolders :)\n",
    "    \n",
    "    - store_as_json_dir: if you want to store your ditionary as json, give your desired json direcotry\n",
    "    \n",
    "    - store_as_excel_dir: if you want to store your ditionary as excel, give your desired excel direcotry\n",
    "    \n",
    "    For using this function, the best practice is to place each folder containing one dicom study in subfolder, under the dicom_dir. \n",
    "    However, you can change finding unique dicom studies, even placed next to each other beacouse I definied the study_unique=f'{first_subfolder}_{study_id}_{study_date}'.\n",
    "    If you want your code to be faster you can chane the study_unique to study_unique=first_subfolder. It makes your code 15% faster, sometimes at the cost of incurrect retrival.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    total_subfolder,total_files=count_subfolders(dicom_dir)\n",
    "    print(f'your direcotry contains {total_subfolder} folders and {total_files} files')\n",
    "    \n",
    "    last_dir_name = os.path.basename(os.path.normpath(dicom_dir))\n",
    "    dicom_data = {last_dir_name: {}}\n",
    "\n",
    "    for root, dirs, files in tqdm(os.walk(dicom_dir), desc=\"Processing directories\", total=total_subfolder,unit='folder'):\n",
    "        if folder_list_name_indicomdir:\n",
    "            split_path = root.replace(dicom_dir, '').split(os.sep)\n",
    "            first_subfolder = split_path[1] if len(split_path) > 1 else \"\"\n",
    "            if first_subfolder not in folder_list_name_indicomdir:\n",
    "                print(f\"\"\"The folder {first_subfolder} was not in your definied list.\"\"\")\n",
    "                continue  # Skip if the first subfolder is not in the user-defined list\n",
    "            \n",
    "        for file in files:\n",
    "            if dicom_validation and not pm.misc.is_dicom(os.path.join(root, file)):\n",
    "                continue # Skip if the it is not dicom file\n",
    "                   \n",
    "\n",
    "            try:\n",
    "                dicom_file = pm.dcmread(os.path.join(root, file))\n",
    "                study_id = get_dicom_tag_value(dicom_file, (0x0020, 0x0010))\n",
    "                dicom_data_number = get_dicom_tag_value(dicom_file, (0x0020, 0x0011))\n",
    "                study_date = get_dicom_tag_value(dicom_file, (0x0008, 0x0020))\n",
    "                split_path = root.replace(dicom_dir, '').split(os.sep)\n",
    "                first_subfolder = split_path[1] if len(split_path) > 1 else \"\"\n",
    "                if study_id and dicom_data_number and study_date:\n",
    "                    study_unique = f'{first_subfolder}_{study_id}_{study_date}' #you can change it for increasing the speed > study_unique=first_subfolder\n",
    "                    if study_unique not in dicom_data[last_dir_name]:\n",
    "                        private_info={'name': get_dicom_tag_value(dicom_file, (0x0010, 0x0010)),\n",
    "                                      'institute': get_dicom_tag_value(dicom_file, (0x0008, 0x0080)),\n",
    "                                      'patient_id': get_dicom_tag_value(dicom_file, (0x0010, 0x0020)),\n",
    "                                      'accession_number':get_dicom_tag_value(dicom_file, (0x0008, 0x0050))\n",
    "                                      }\n",
    "                        \n",
    "                        dicom_data[last_dir_name][study_unique] = {\n",
    "                            'dir_to_root': get_path_to_first_subfolder(root, first_subfolder),\n",
    "                            'study_description': get_dicom_tag_value(dicom_file, (0x0008, 0x1030)),\n",
    "                            'date': study_date,\n",
    "                            'age': get_dicom_tag_value(dicom_file, (0x0010, 0x1010)),\n",
    "                            'sex': get_dicom_tag_value(dicom_file, (0x0010, 0x0040)),\n",
    "                            'manufacture_model': get_dicom_tag_value(dicom_file, (0x0008, 0x1090)),\n",
    "                            'manufacture_brand': get_dicom_tag_value(dicom_file, (0x0008, 0x0070)),\n",
    "                            'manufacture_brand': get_dicom_tag_value(dicom_file, (0x0008, 0x0070)),\n",
    "                            'protocol': get_dicom_tag_value(dicom_file, (0x0018, 0x1030)),\n",
    "                            'study_id': study_id,\n",
    "                            'patient_weight': get_dicom_tag_value(dicom_file, (0x0010, 0x1030)),\n",
    "                            'Image_type': get_dicom_tag_value(dicom_file, (0x0008, 0x0008)),\n",
    "                            'body_part': get_dicom_tag_value(dicom_file, (0x0018, 0x0015)),\n",
    "                            'modalitty':get_dicom_tag_value(dicom_file, (0x0008, 0x0050)),\n",
    "                            'private_info':private_info,\n",
    "                            'image_dicom_data_list': {}\n",
    "                        }\n",
    "\n",
    "                    \n",
    "\n",
    "                    dicom_data_info = {\n",
    "                        'dicom_data_description': get_dicom_tag_value(dicom_file, (0x0008, 0x103E)),\n",
    "                        'body_part': get_dicom_tag_value(dicom_file, (0x0018, 0x0015)),\n",
    "                        'slice_thickness': get_dicom_tag_value(dicom_file, (0x0018, 0x0050)),\n",
    "                        'Image_comment': get_dicom_tag_value(dicom_file, (0x0020, 0x4000)),\n",
    "                        'kvp': get_dicom_tag_value(dicom_file, (0x0018, 0x0060)),\n",
    "                        'exposure': get_dicom_tag_value(dicom_file, (0x0018, 0x1152)),\n",
    "                        'exposure_time': get_dicom_tag_value(dicom_file, (0x0018, 0x1150)),\n",
    "                    }\n",
    "                    dicom_data[last_dir_name][study_unique]['image_dicom_data_list'][dicom_data_number] = dicom_data_info\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"\"\"Error reading for {file}::: {e} \\n \"\"\")\n",
    "                continue\n",
    "            \n",
    "    if store_as_json_dir is not None:\n",
    "        try:\n",
    "            json_read = json.dumps(dicom_data, indent=4, cls=CustomJSONEncoder)\n",
    "            store_as_json_dir=str(store_as_json_dir)\n",
    "            store_as_json_dir=ensure_json_extension(store_as_json_dir)\n",
    "            with open(store_as_json_dir, 'w') as json_file:\n",
    "                json_file.write(json_read)\n",
    "            print(f\"\"\"Json stored at :::\"\"\")\n",
    "            display(create_clickable_dir_path(store_as_json_dir))         \n",
    "        except:\n",
    "            print(f\"\"\"Error storing the json ::: {e} \\n \"\"\")\n",
    "            \n",
    "    if store_as_excel_dir is not None:\n",
    "        try:\n",
    "            dataframes = []\n",
    "            for key, value in dicom_data.items():\n",
    "                # Convert value to DataFrame if necessary\n",
    "                df = pd.DataFrame(value)\n",
    "                # Add the key as a new column or as part of the index\n",
    "                df['Key'] = key  # Add key as a column\n",
    "                # df = df.set_index(['Key'], append=True)  # Add key as part of a MultiIndex\n",
    "                dataframes.append(df)\n",
    "\n",
    "            # Concatenate all dataframes\n",
    "            df2 = pd.concat(dataframes).T\n",
    "            store_as_excel_dir=str(store_as_excel_dir)\n",
    "            store_as_excel_dir=ensure_excel_extension(store_as_excel_dir)\n",
    "            df2.to_excel(store_as_excel_dir)\n",
    "            print(f\"\"\"Excel stored at :::\"\"\")\n",
    "            display(create_clickable_dir_path(store_as_excel_dir))          \n",
    "        except:\n",
    "            print(f\"\"\"Error storing the excel ::: {e} \\n \"\"\")\n",
    "            \n",
    "                                 \n",
    "    return dicom_data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final\n",
    "\n",
    "# Prepare for anonymization\n",
    "# First, we want to prepare the dicoms. In previous steps we sotred each dicom sutdy in one folder. \n",
    "# However, for many cases sesies are stored in different folders 'SR_1', 'SR_2', etc.\n",
    "# This code will add the fodler name at the begiining of dicom files within that folder, and then transfer all files to the main dicom study folder.\n",
    "# Also, if all dicoms are stored in one place, 1, 2, 3, ..., 1500; We will add series number at the beging of them. So we can choose relvant series for tranfering them to server.\n",
    "\n",
    "\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import HTML\n",
    "import pydicom\n",
    "import shutil\n",
    "\n",
    "def create_clickable_dir_path(dir_path):\n",
    "    # Convert the directory path to a file URL\n",
    "    file_url = f\"{dir_path}\"\n",
    "    return HTML(f'<a href=\"{file_url}\" target=\"_blank\">{dir_path}</a>')\n",
    "\n",
    "\n",
    "def add_series_2beginingoffile(directory, adding_directory_2progresbar=''):\n",
    "    renamed_count = 0\n",
    "    skipped_count = 0\n",
    "    for filename in tqdm(os.listdir(directory),desc=f'Adding series name {adding_directory_2progresbar} at the beggining of files', unit='folders'):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "\n",
    "        # Check if it's a file and has a DICOM extension (optional)\n",
    "        if os.path.isfile(file_path):\n",
    "            \n",
    "            try:\n",
    "                # Read the DICOM file\n",
    "                dicom_file = pydicom.dcmread(file_path)\n",
    "\n",
    "                # Get the series number\n",
    "                series_number = dicom_file.SeriesNumber\n",
    "\n",
    "                # Create new file name with series number prefix\n",
    "                new_filename = f\"SR{series_number}_{filename}\"\n",
    "                new_file_path = os.path.join(directory, new_filename)\n",
    "\n",
    "                # Rename (replace) the file\n",
    "                os.rename(file_path, new_file_path)\n",
    "                renamed_count += 1\n",
    "\n",
    "            except Exception as e:\n",
    "                skipped_count += 1\n",
    "                \n",
    "    print(f\"Total files skipped: {skipped_count}\")\n",
    "    print(f\"Total files renamed: {renamed_count}\")\n",
    "\n",
    "def add_subfolder_name_and_move(main_directory,adding_directory_2progresbar=''):\n",
    "    for folder in tqdm(os.listdir(main_directory),desc=f'Adding series name {adding_directory_2progresbar} at the beggining of files', unit='folders'):\n",
    "        folder_path = os.path.join(main_directory, folder)\n",
    "\n",
    "        # Check if it's a directory\n",
    "        if os.path.isdir(folder_path):\n",
    "            for file in os.listdir(folder_path):\n",
    "                file_path = os.path.join(folder_path, file)\n",
    "\n",
    "                # Check if it's a file\n",
    "                if os.path.isfile(file_path):\n",
    "                    # Create new file name with subfolder prefix\n",
    "                    new_filename = f\"{folder}_{file}\"\n",
    "                    new_file_path = os.path.join(main_directory, new_filename)\n",
    "\n",
    "                    # Move and rename file\n",
    "                    shutil.move(file_path, new_file_path)\n",
    "                    print(f\"Moved and renamed: {new_file_path}\")\n",
    "                    \n",
    "def add_subfolder_name_and_move(main_directory,adding_directory_2progresbar=''):\n",
    "    files_moved = 0  # Initialize a counter for the number of files moved\n",
    "\n",
    "    for folder in tqdm(os.listdir(main_directory),desc=f'Adding series name {adding_directory_2progresbar} at the beggining of files', unit='folders'):\n",
    "        folder_path = os.path.join(main_directory, folder)\n",
    "\n",
    "        # Check if it's a directory\n",
    "        if os.path.isdir(folder_path):\n",
    "            for file in os.listdir(folder_path):\n",
    "                file_path = os.path.join(folder_path, file)\n",
    "\n",
    "                # Check if it's a file\n",
    "                if os.path.isfile(file_path):\n",
    "                    # Create new file name with subfolder prefix\n",
    "                    new_filename = f\"{folder}_{file}\"\n",
    "                    new_file_path = os.path.join(main_directory, new_filename)\n",
    "\n",
    "                    # Move and rename file\n",
    "                    shutil.move(file_path, new_file_path)\n",
    "                    files_moved += 1  # Increment the counter\n",
    "\n",
    "\n",
    "    # Print the total number of files moved\n",
    "    print(f\"Total number of files moved: {files_moved}\")\n",
    "\n",
    "    # Remove empty subfolders\n",
    "    empty_folder_removed=0\n",
    "    for folder in os.listdir(main_directory):\n",
    "        folder_path = os.path.join(main_directory, folder)\n",
    "        \n",
    "        # Check if the folder is empty and a directory\n",
    "        if os.path.isdir(folder_path) and not os.listdir(folder_path):\n",
    "            os.rmdir(folder_path)\n",
    "            empty_folder_removed +=1\n",
    "            print(f\"Removed empty folder: {folder_path}\")\n",
    "\n",
    "    remaining_folders = sum(os.path.isdir(os.path.join(main_directory, d)) for d in os.listdir(main_directory))\n",
    "    \n",
    "    print(f\"Number of empty folders removed: {empty_folder_removed}\")\n",
    "    print(f\"Number of remaining folders: {remaining_folders}\")\n",
    "\n",
    "\n",
    "def folderedstudy_and_addingseriesname_handler(main_directory):\n",
    "\n",
    "    for folder in tqdm(os.listdir(main_directory), desc='Reading folders withing directory', unit='files'):\n",
    "        folder_path = os.path.join(main_directory, folder)\n",
    "        \n",
    "        if os.path.isdir(folder_path):\n",
    "            subfolders = [name for name in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, name))]\n",
    "            count_subfolders = len(subfolders)\n",
    "            if count_subfolders > 0:\n",
    "                print(f\"#{count_subfolders} Subfolders within: \")\n",
    "                display(create_clickable_dir_path(folder_path))\n",
    "                add_subfolder_name_and_move(folder_path,adding_directory_2progresbar=folder_path)\n",
    "                add_series_2beginingoffile(folder_path,adding_directory_2progresbar=folder_path)\n",
    "                \n",
    "            else:\n",
    "                print(f\"No subfolder exists in:\")\n",
    "                display(create_clickable_dir_path(folder_path))\n",
    "                add_series_2beginingoffile(folder_path,adding_directory_2progresbar=folder_path)\n",
    "\n",
    "        \n",
    "        print('-----------------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Files: Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#storeing the patient inforamtion for future retrival befor anonymization (=pseudonymization)--------------\n",
    "dicom_dir=r\"C:\\PanCanAID_Valid_Case_20231212\" \n",
    "save_dir_json=r'C:\\PanCanAID_Valid_Case_20231212\\20231212_59Case.json'\n",
    "save_dir_xlsx=r'C:\\PanCanAID_Valid_Case_20231212\\20231212_59Case.xlsx'\n",
    "\n",
    "dicom_dic=get_dicomdir_give_dicomdicom_datadic(\n",
    "    dicom_dir, #direcotry that you want to read, usually dicom studies should be in one folder, preferably with patient unique id/name\n",
    "                                     dicom_validation=True, #this will check wether the file in the loop is dicom or not. Although make it slower, I recommend using it to ensure only dicom files go through loop \n",
    "                                     folder_list_name_indicomdir=None, #In your dicom_dir you can include list of folders name that you want to read. It will not read other folders. Kepp in mind that this will look into subfolders in the main folder, and not the subfolders of subfolders :)\n",
    "                                     store_as_json_dir=save_dir_json, #if you want to store your ditionary as json, give your desired json direcotry\n",
    "                                     store_as_excel_dir=save_dir_xlsx #if you want to store your ditionary as excel, give your desired excel direcotry\n",
    "                                     )\n",
    "\n",
    "\n",
    "\n",
    "#Handling files stored in subfolders and adding series number at the begining of file names--------------\n",
    "dicom_dir=r\"C:\\PanCanAID_Valid_Case_20231212\" \n",
    "\n",
    "folderedstudy_and_addingseriesname_handler(dicom_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anonymize: Function and library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pydicom as pm\n",
    "import os\n",
    "from tqdm.notebook import tqdm \n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anonymize_dicommeta_dic={\n",
    "    (0008,0020)     #\n",
    "    (0008,0021)     #\n",
    "    (0008,0022)     #\n",
    "    (0008,0030)     #study time\n",
    "    (0008,0031)     #sreies time\n",
    "    (0008,0032)     #acquisition time\n",
    "    (0008,0033)     #content time\n",
    "    (0008,0050)     #accesion number\n",
    "    (0008,1050)      # refering physian\n",
    "    (0008,1070)      #operator name\n",
    "    ()      #\n",
    "    ()      #\n",
    "    ()      #\n",
    "    ()      #\n",
    "    ()      #\n",
    "    ()      #\n",
    "    ()      #\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def anonymize_dicom_file(dicom,dic_of_tags2anonymize=[]):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dicom anonymizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "InputPath\n",
    "OutputPath "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIcognito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "import pydicom\n",
    "import dicognito.anonymizer\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "\n",
    "anonymizer = dicognito.anonymizer.Anonymizer()\n",
    "input_dir=r'C:\\PanCanAID_Valid_Case_20231212\\1001_1'\n",
    "output_dir=r'C:\\PanCanAID_Valid_Case_20231212_Anonymized\\1001_1'\n",
    "\n",
    "\n",
    "for root, dirs, files in tqdm(os.walk(input_dir), desc=\"Processing directories\",unit='dcm file'):\n",
    "    for file in files:\n",
    "        dir_dcm_file=os.path.join(root, file)\n",
    "        with pydicom.dcmread(dir_dcm_file) as dataset:\n",
    "            anonymizer.anonymize(dataset)\n",
    "            dataset.save_as(output_dir+\"clean-\" + file)\n",
    "        \n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
