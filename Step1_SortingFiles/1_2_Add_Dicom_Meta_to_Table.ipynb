{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer dicom files to pseudonymization destination\n",
    "\n",
    "<details>\n",
    "<summary>STEP 1 BIG PICTURE</summary>\n",
    "We collected data from centers in folders, named as patient ID (e.g. admission). We want to clean these directories, so \n",
    "I: Each CT study is placed in one folder\n",
    "II: Store cases in an excel file, with its dicom files in the table, and all other variables (outcome, clinical, pathology data) stored here. We call this master key, which also contains patient id (un-anonymized) along with the key for anonymization.\n",
    "III: Transfer dicom-pnly files to new destination and anonymize these images.\n",
    "</details>\n",
    "<details>\n",
    "<summary>PREVIOUS STEP</summary>\n",
    "We find all file types in our directory (I ran the code for each center sepratly. Having 1.5 terabytes of informaiton and ~1800 cases, it collectivly took 30 hours on a RTX3080Ti labtob and Corei912gen and 32Ram)\n",
    "</details>\n",
    "<details>\n",
    "<summary>THIS STEP</summary>\n",
    "In this step we will add unique dicom meta data about patient info, study info, and series info\n",
    "</details>\n",
    "<details>\n",
    "<summary>NEXT STEP</summary>\n",
    "Finding dicom meta data\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARCHIVED CODES (TRASH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydicom as pm\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def rename_duplicate_columns(df):\n",
    "    \"\"\"Rename duplicate columns in the DataFrame.\"\"\"\n",
    "    cols = pd.Series(df.columns)\n",
    "    for dup in cols[cols.duplicated()].unique(): \n",
    "        cols[cols[cols == dup].index.values.tolist()] = [dup + '_DUP' + str(i) if i != 0 else dup for i in range(sum(cols == dup))]\n",
    "    df.columns = cols\n",
    "\n",
    "Hospital_name= \"Guilan\"\n",
    "directory_shortlist=f\"D:\\Data\\Big Pancreas (CT, EUS)\\Raw Data Hospital\\{Hospital_name}_data_short_just_dcm.xlsx\"\n",
    "directory_longlist=f\"D:\\Data\\Big Pancreas (CT, EUS)\\Raw Data Hospital\\{Hospital_name}_data.csv\"\n",
    "\n",
    "\n",
    "directory_longlist=pd.read_csv(directory_longlist)\n",
    "directory_longlist_dcm=directory_longlist[directory_longlist['If_dicom']==True]\n",
    "directory_longlist=pd.read_csv(directory_longlist)\n",
    "directory_longlist_dcm=directory_longlist[directory_longlist['If_dicom']==True]\n",
    "directory_longlist_dcm=directory_longlist_dcm.reset_index()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import pydicom as pm\n",
    "\n",
    "dcminfo_list = []  # List to store the individual DataFrame pieces\n",
    "\n",
    "for i in range(1, len(directory_longlist_dcm)):\n",
    "    dir_path = os.path.join(directory_longlist_dcm.iloc[i][4], directory_longlist_dcm.iloc[i][3])\n",
    "    ds = pm.dcmread(dir_path)\n",
    "    ds = pd.DataFrame(ds.values())\n",
    "    ds[0] = ds[0].apply(lambda x: pm.dataelem.DataElement_from_raw(x) if isinstance(x, pm.dataelem.RawDataElement) else x)\n",
    "    ds['name'] = ds[0].apply(lambda x: x.name)\n",
    "    ds['value'] = ds[0].apply(lambda x: x.value)\n",
    "    ds = ds[['name', 'value']]\n",
    "    ds = ds.T\n",
    "    new_header = ds.iloc[0]  # First row as header\n",
    "    ds = ds[1:]  # Taking the rest of the data\n",
    "    ds.columns = new_header  # Setting the new header\n",
    "    ds['to_directory'] = dir_path\n",
    "    ds['key2csv']=directory_longlist_dcm['Unnamed: 0'][i]\n",
    "    \n",
    "\n",
    "    dcminfo_list.append(ds)\n",
    "\n",
    "for df in dcminfo_list:\n",
    "    rename_duplicate_columns(df)\n",
    "\n",
    "\n",
    "dcminfo_all=pd.concat(dcminfo_list, ignore_index=True, sort=False)\n",
    "dcminfo_all\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
